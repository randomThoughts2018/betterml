# betterml

> We build a model, and we get some *metrics* out of it

- How do we know, which *model* will generalize better?
  - Having a validation data strategy, that mimics real production environment. 
  - Kaggle ? 
- Chossing the right *metric* for a machine learning problem
  - [Chossing right metric: Regression](https://towardsdatascience.com/choosing-the-right-metric-for-machine-learning-models-part-1-a99d7d7414e4)
  - [Chossing right metric: Classification](https://towardsdatascience.com/choosing-the-right-metric-for-evaluating-machine-learning-models-part-2-86d5649a5428)
  
- How do we deeply understand our data in a model driven way, and make our model better
  - feature importance
  - [rfimp blog](http://parrt.cs.usfca.edu/doc/rf-importance/index.html)
  - [Shap blog](https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27)
  - [Shap for Trees](https://arxiv.org/pdf/1802.03888.pdf)
  
  
- DataSets to be used 
  - [two-sigma-connect-rental-listing-inquiries](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/data)
  
- Models to Learn
  - Neural Networks 
  - Shap Framework 
  - Cat Boost 
  - LightGBM
  - XGBoost 
  - Random Forest
